{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Heart Disease classification\n",
    "\n",
    "https://www.kaggle.com/ayushjain001/regularization-model-on-heart-dataset/data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T17:35:17.47237Z",
     "iopub.status.busy": "2022-02-16T17:35:17.471604Z",
     "iopub.status.idle": "2022-02-16T17:35:17.48535Z",
     "shell.execute_reply": "2022-02-16T17:35:17.484454Z",
     "shell.execute_reply.started": "2022-02-16T17:35:17.472307Z"
    }
   },
   "outputs": [],
   "source": [
    "#imports\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from math import ceil\n",
    "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder,OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "import plotly.express as px\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix ,  plot_roc_curve , classification_report , accuracy_score\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T17:35:19.150676Z",
     "iopub.status.busy": "2022-02-16T17:35:19.150376Z",
     "iopub.status.idle": "2022-02-16T17:35:19.174442Z",
     "shell.execute_reply": "2022-02-16T17:35:19.173616Z",
     "shell.execute_reply.started": "2022-02-16T17:35:19.150631Z"
    }
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"../input/heart-failure-prediction/heart.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Age: age of the patient [years]\n",
    "\n",
    "Sex: sex of the patient [M: Male, F: Female]\n",
    "\n",
    "ChestPainType: chest pain type [TA: Typical Angina, ATA: Atypical Angina, NAP: Non-Anginal Pain, ASY: Asymptomatic]\n",
    "\n",
    "RestingBP: resting blood pressure [mm Hg]\n",
    "\n",
    "Cholesterol: serum cholesterol [mm/dl]\n",
    "\n",
    "FastingBS: fasting blood sugar [1: if FastingBS > 120 mg/dl, 0: otherwise]\n",
    "\n",
    "RestingECG: resting electrocardiogram results [Normal: Normal, ST: having ST-T wave abnormality (T wave inversions\n",
    "and/or ST elevation or depression of > 0.05 mV), LVH: showing probable or definite left ventricular hypertrophy by Estes' criteria]\n",
    "\n",
    "MaxHR: maximum heart rate achieved [Numeric value between 60 and 202]\n",
    "\n",
    "ExerciseAngina: exercise-induced angina [Y: Yes, N: No]\n",
    "\n",
    "Oldpeak: oldpeak = ST [Numeric value measured in depression]\n",
    "\n",
    "ST_Slope: the slope of the peak exercise ST segment [Up: upsloping, Flat: flat, Down: downsloping]\n",
    "\n",
    "HeartDisease: output class [1: heart disease, 0: Normal]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T17:35:23.815575Z",
     "iopub.status.busy": "2022-02-16T17:35:23.814739Z",
     "iopub.status.idle": "2022-02-16T17:35:23.848658Z",
     "shell.execute_reply": "2022-02-16T17:35:23.847822Z",
     "shell.execute_reply.started": "2022-02-16T17:35:23.815504Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"shape of the df :   {}\".format(df.shape))\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T17:36:09.978666Z",
     "iopub.status.busy": "2022-02-16T17:36:09.978151Z",
     "iopub.status.idle": "2022-02-16T17:36:09.984716Z",
     "shell.execute_reply": "2022-02-16T17:36:09.983869Z",
     "shell.execute_reply.started": "2022-02-16T17:36:09.97861Z"
    }
   },
   "outputs": [],
   "source": [
    "#we can  see max cholesterol mm/dl wich can be an outlier, other features don't have some\n",
    "df[\"Cholesterol\"].value_counts()\n",
    "df=df[df[\"Cholesterol\"]<500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T17:36:11.900177Z",
     "iopub.status.busy": "2022-02-16T17:36:11.899711Z",
     "iopub.status.idle": "2022-02-16T17:36:11.908697Z",
     "shell.execute_reply": "2022-02-16T17:36:11.908054Z",
     "shell.execute_reply.started": "2022-02-16T17:36:11.900124Z"
    }
   },
   "outputs": [],
   "source": [
    "df.isnull().sum()\n",
    "#no missing value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Countplots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T17:36:15.066891Z",
     "iopub.status.busy": "2022-02-16T17:36:15.066589Z",
     "iopub.status.idle": "2022-02-16T17:36:17.606248Z",
     "shell.execute_reply": "2022-02-16T17:36:17.605557Z",
     "shell.execute_reply.started": "2022-02-16T17:36:15.066847Z"
    }
   },
   "outputs": [],
   "source": [
    "def countplot(df,max_columns,val,figsize,title_size=20,title=\"\"):\n",
    "    l=len(df.columns)\n",
    "    ligns=ceil(l/max_columns)\n",
    "    fig=plt.figure(1,figsize=figsize)\n",
    "    i=1\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if len(pd.unique(df[col]))<val:\n",
    "            plt.subplot(ligns,max_columns,i)\n",
    "            plt.title(col, fontsize=title_size)\n",
    "            i=i+1\n",
    "            sns.countplot(data = df, x=col )\n",
    "    fig.tight_layout(pad=3.0)\n",
    "    \n",
    "    fig.suptitle(title)\n",
    "    plt.show()\n",
    "    \n",
    "title=\"Different Countplots\"\n",
    "countplot(df,3,10,(80,80),80)\n",
    "#countsplot dataframe,columns spliting,max_uniquevalues,figsize,title,title_size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see not all data are homogeneous for example there are more men \n",
    "\n",
    "the more common chest is 'ASY': Asymptomatic\n",
    "\n",
    "more common FastingBS (fasting blood sugar):  0 wich means:  FastingBS <= 120 mg/dl \n",
    "\n",
    "more common resting ECG (resting electrocardiogram results): normal\n",
    "\n",
    "more common ExerciseAngine: No\n",
    "\n",
    "more common ST_slope(the slope of the peak exercise ST segment ): Flat\n",
    "\n",
    "most people have heart disease (in the dataframe)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T17:36:23.984993Z",
     "iopub.status.busy": "2022-02-16T17:36:23.984012Z",
     "iopub.status.idle": "2022-02-16T17:36:24.80163Z",
     "shell.execute_reply": "2022-02-16T17:36:24.800795Z",
     "shell.execute_reply.started": "2022-02-16T17:36:23.984942Z"
    }
   },
   "outputs": [],
   "source": [
    "figure2=plt.figure(2,figsize=(15,10))\n",
    "\n",
    "plt.subplot(3,2,1)\n",
    "sns.violinplot(data=df,x=\"Cholesterol\")\n",
    "plt.subplot(3,2,2)\n",
    "sns.violinplot(data=df,x=\"Age\")\n",
    "plt.subplot(3,2,3)\n",
    "sns.violinplot(data=df,x=\"Oldpeak\")\n",
    "plt.subplot(3,2,4)\n",
    "sns.violinplot(data =df, x=\"MaxHR\")\n",
    "plt.subplot(3,2,5)\n",
    "sns.violinplot(data=df,x=\"RestingBP\")\n",
    "plt.suptitle(\"Repartition of Cholesterol,Age,MaxHR,Oldpeak,RestingBP\")\n",
    "\n",
    "\n",
    "figure2.tight_layout(pad=3.0)\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see most of the people are between 50-60\n",
    "\n",
    "the Cholesterol rate is concentrated in the 200-300 mm/dl range\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Principal component analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T17:36:29.055157Z",
     "iopub.status.busy": "2022-02-16T17:36:29.054889Z",
     "iopub.status.idle": "2022-02-16T17:36:29.07873Z",
     "shell.execute_reply": "2022-02-16T17:36:29.077637Z",
     "shell.execute_reply.started": "2022-02-16T17:36:29.055129Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#encoding\n",
    "df[\"Sex\"] = df[\"Sex\"].astype('category')\n",
    "df[\"Sex\"] = df[\"Sex\"].cat.codes\n",
    "df[\"ChestPainType\"] = df[\"ChestPainType\"].astype('category')\n",
    "df[\"ChestPainType\"] = df[\"ChestPainType\"].cat.codes\n",
    "\n",
    "df[\"RestingECG\"] = df[\"RestingECG\"].astype('category')\n",
    "df[\"RestingECG\"] = df[\"RestingECG\"].cat.codes\n",
    "\n",
    "df[\"ExerciseAngina\"] = df[\"ExerciseAngina\"].astype('category')\n",
    "df[\"ExerciseAngina\"] = df[\"ExerciseAngina\"].cat.codes\n",
    "\n",
    "df[\"ST_Slope\"] = df[\"ST_Slope\"].astype('category')\n",
    "df[\"ST_Slope\"] = df[\"ST_Slope\"].cat.codes\n",
    "\n",
    "X=df.drop([\"HeartDisease\"],axis=1)\n",
    "y=df[\"HeartDisease\"]\n",
    "X=StandardScaler().fit_transform(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ploting heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T17:59:57.156969Z",
     "iopub.status.busy": "2022-02-16T17:59:57.156641Z",
     "iopub.status.idle": "2022-02-16T17:59:59.315706Z",
     "shell.execute_reply": "2022-02-16T17:59:59.315046Z",
     "shell.execute_reply.started": "2022-02-16T17:59:57.156934Z"
    }
   },
   "outputs": [],
   "source": [
    "figsns=plt.figure(7,figsize=(25,25))\n",
    "\n",
    "sns.heatmap(pd.get_dummies(df).corr(),annot=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T17:36:35.182712Z",
     "iopub.status.busy": "2022-02-16T17:36:35.182446Z",
     "iopub.status.idle": "2022-02-16T17:36:35.211788Z",
     "shell.execute_reply": "2022-02-16T17:36:35.210778Z",
     "shell.execute_reply.started": "2022-02-16T17:36:35.182683Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#two principal components\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "principalComponents=pca.fit_transform(df)\n",
    "\n",
    "principalDf = pd.DataFrame(data = principalComponents\n",
    "             , columns = ['principal component 1', 'principal component 2'])\n",
    "finalDf = pd.concat([principalDf, df[['HeartDisease']]], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T17:36:50.815033Z",
     "iopub.status.busy": "2022-02-16T17:36:50.814736Z",
     "iopub.status.idle": "2022-02-16T17:36:51.154959Z",
     "shell.execute_reply": "2022-02-16T17:36:51.154119Z",
     "shell.execute_reply.started": "2022-02-16T17:36:50.815004Z"
    }
   },
   "outputs": [],
   "source": [
    "total_var = pca.explained_variance_ratio_.sum() * 100\n",
    "\n",
    "fig = plt.figure(figsize = (8,8))\n",
    "ax = fig.add_subplot(1,1,1) \n",
    "ax.set_xlabel('Principal Component 1', fontsize = 15)\n",
    "ax.set_ylabel('Principal Component 2', fontsize = 15)\n",
    "ax.set_title('2 component PCA', fontsize = 20)\n",
    "targets = df[\"HeartDisease\"].values\n",
    "\n",
    "\n",
    "colors = ['r', 'g']\n",
    "for target, color in zip(targets,colors):\n",
    "    indicesToKeep = finalDf['HeartDisease'] == target\n",
    "    ax.scatter(finalDf.loc[indicesToKeep, 'principal component 1']\n",
    "               , finalDf.loc[indicesToKeep, 'principal component 2']\n",
    "               , c = color\n",
    "               , s = 50)\n",
    "ax.legend(targets)\n",
    "ax.grid()\n",
    "\n",
    "total_var = pca.explained_variance_ratio_.sum() * 100\n",
    "print(\"total variance {:.2f}  \\n  explained_var_ratio{}\".format(total_var,pca.explained_variance_ratio_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First component countains 92% of the variance and the second one 5%\n",
    "\n",
    "We can clearly see the class HeartDisease 1 separated with the -200 value on the principal component 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "three principal component analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T17:37:39.576931Z",
     "iopub.status.busy": "2022-02-16T17:37:39.576598Z",
     "iopub.status.idle": "2022-02-16T17:37:40.655882Z",
     "shell.execute_reply": "2022-02-16T17:37:40.654894Z",
     "shell.execute_reply.started": "2022-02-16T17:37:39.576891Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "components = pca.fit_transform(X)\n",
    "\n",
    "\n",
    "fig = px.scatter_3d(\n",
    "    components, x=0, y=1, z=2, color=df['HeartDisease'],\n",
    "    title=f'Total Explained Variance: {total_var:.2f}%',\n",
    "    labels={'0': 'PC 1', '1': 'PC 2', '2': 'PC 3'}\n",
    ")\n",
    "fig.show()\n",
    "print(\"explained_var_ratio{}\".format(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first component countains 25% of the Variance\n",
    "\n",
    "second component countais 13% of the variance\n",
    "\n",
    "third component countais 10% of the variance\n",
    "\n",
    "the class 0 and 1 seems relatively  separable with these 3 components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T17:38:03.250689Z",
     "iopub.status.busy": "2022-02-16T17:38:03.250388Z",
     "iopub.status.idle": "2022-02-16T17:38:03.271841Z",
     "shell.execute_reply": "2022-02-16T17:38:03.271173Z",
     "shell.execute_reply.started": "2022-02-16T17:38:03.250655Z"
    }
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"../input/heart-failure-prediction/heart.csv\")\n",
    "\n",
    "X=pd.get_dummies(df.drop([\"HeartDisease\"],axis=1))\n",
    "y=df[\"HeartDisease\"]\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T17:38:20.116891Z",
     "iopub.status.busy": "2022-02-16T17:38:20.11644Z",
     "iopub.status.idle": "2022-02-16T17:38:20.143063Z",
     "shell.execute_reply": "2022-02-16T17:38:20.142116Z",
     "shell.execute_reply.started": "2022-02-16T17:38:20.11684Z"
    }
   },
   "outputs": [],
   "source": [
    "pca = PCA(.95)\n",
    "#minimum number of components so that 95% of the variance is retained\n",
    "pca.fit(X_train)\n",
    "print(\"number of component retained {}\".format(pca.n_components_))\n",
    "\n",
    "\n",
    "X_train_pca=pca.transform(X_train)\n",
    "X_test_pca=pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T17:39:41.191522Z",
     "iopub.status.busy": "2022-02-16T17:39:41.19123Z",
     "iopub.status.idle": "2022-02-16T17:39:57.071917Z",
     "shell.execute_reply": "2022-02-16T17:39:57.071323Z",
     "shell.execute_reply.started": "2022-02-16T17:39:41.191493Z"
    }
   },
   "outputs": [],
   "source": [
    "#-----------------------MLP grid search CV-----------------------------\n",
    "mlp=make_pipeline(RobustScaler(),MLPClassifier(max_iter=10000))\n",
    "param_grid={\n",
    "            'mlpclassifier__hidden_layer_sizes':(range(1,4)),\n",
    "            'mlpclassifier__solver':['lbfgs','sgd'],\n",
    "            'mlpclassifier__activation':[\"logistic\", \"tanh\", \"relu\"]\n",
    "           }                             \n",
    "grid= GridSearchCV(mlp,param_grid=param_grid,cv=5)\n",
    "grid.fit(X_train_pca,y_train)\n",
    "print(\"best train cv score : {:.3f}, with parameters : {}\".format(grid.best_score_,grid.best_params_))\n",
    "mlp=grid.best_estimator_\n",
    "print(\"test score {:.3f}\".format(mlp.score(X_test_pca,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T17:40:03.048616Z",
     "iopub.status.busy": "2022-02-16T17:40:03.048059Z",
     "iopub.status.idle": "2022-02-16T17:54:43.616235Z",
     "shell.execute_reply": "2022-02-16T17:54:43.615293Z",
     "shell.execute_reply.started": "2022-02-16T17:40:03.048579Z"
    }
   },
   "outputs": [],
   "source": [
    "#--------------------RandomForest--------------------\n",
    "rdm=make_pipeline(RobustScaler(),RandomForestClassifier())\n",
    "\n",
    "param_rdm = {'robustscaler__with_centering':[True,False],\n",
    "             'robustscaler__with_scaling':[True,False],\n",
    "             'randomforestclassifier__n_estimators': [200, 500],\n",
    "             'randomforestclassifier__max_features': ['auto', 'sqrt', 'log2'],\n",
    "             'randomforestclassifier__max_depth' : [4,5,6,7,8],\n",
    "             'randomforestclassifier__criterion' :['gini', 'entropy'],\n",
    "            }\n",
    "\n",
    "grid_rdm=GridSearchCV(rdm,param_rdm,cv=5)\n",
    "grid_rdm.fit(X_train_pca,y_train)\n",
    "rdm=grid_rdm.best_estimator_\n",
    "print(\"best score rdm {:.3f} aw parameters :{}\".format(grid_rdm.best_score_,grid_rdm.best_params_))\n",
    "print(\"test score {:.3f}\".format(rdm.score(X_test_pca,y_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/auto_examples/model_selection/plot_learning_curve.html#sphx-glr-auto-examples-model-selection-plot-learning-curve-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T17:54:48.025648Z",
     "iopub.status.busy": "2022-02-16T17:54:48.025345Z",
     "iopub.status.idle": "2022-02-16T17:54:48.045461Z",
     "shell.execute_reply": "2022-02-16T17:54:48.044432Z",
     "shell.execute_reply.started": "2022-02-16T17:54:48.025618Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_learning_curve(\n",
    "    estimator,\n",
    "    title,\n",
    "    X,\n",
    "    y,\n",
    "    axes=None,\n",
    "    ylim=None,\n",
    "    cv=None,\n",
    "    n_jobs=None,\n",
    "    train_sizes=np.linspace(0.1, 1.0, 5),\n",
    "):\n",
    "    if axes is None:\n",
    "        _, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
    "\n",
    "    axes[0].set_title(title)\n",
    "    if ylim is not None:\n",
    "        axes[0].set_ylim(*ylim)\n",
    "    axes[0].set_xlabel(\"Training examples\")\n",
    "    axes[0].set_ylabel(\"Score\")\n",
    "\n",
    "    train_sizes, train_scores, test_scores, fit_times, _ = learning_curve(\n",
    "        estimator,\n",
    "        X,\n",
    "        y,\n",
    "        cv=cv,\n",
    "        n_jobs=n_jobs,\n",
    "        train_sizes=train_sizes,\n",
    "        return_times=True,\n",
    "    )\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    fit_times_mean = np.mean(fit_times, axis=1)\n",
    "    fit_times_std = np.std(fit_times, axis=1)\n",
    "\n",
    "    # Plot learning curve\n",
    "    axes[0].grid()\n",
    "    axes[0].fill_between(\n",
    "        train_sizes,\n",
    "        train_scores_mean - train_scores_std,\n",
    "        train_scores_mean + train_scores_std,\n",
    "        alpha=0.1,\n",
    "        color=\"r\",\n",
    "    )\n",
    "    axes[0].fill_between(\n",
    "        train_sizes,\n",
    "        test_scores_mean - test_scores_std,\n",
    "        test_scores_mean + test_scores_std,\n",
    "        alpha=0.1,\n",
    "        color=\"g\",\n",
    "    )\n",
    "    axes[0].plot(\n",
    "        train_sizes, train_scores_mean, \"o-\", color=\"r\", label=\"Training score\"\n",
    "    )\n",
    "    axes[0].plot(\n",
    "        train_sizes, test_scores_mean, \"o-\", color=\"g\", label=\"Cross-validation score\"\n",
    "    )\n",
    "    axes[0].legend(loc=\"best\")\n",
    "\n",
    "    # Plot n_samples vs fit_times\n",
    "    axes[1].grid()\n",
    "    axes[1].plot(train_sizes, fit_times_mean, \"o-\")\n",
    "    axes[1].fill_between(\n",
    "        train_sizes,\n",
    "        fit_times_mean - fit_times_std,\n",
    "        fit_times_mean + fit_times_std,\n",
    "        alpha=0.1,\n",
    "    )\n",
    "    axes[1].set_xlabel(\"Training examples\")\n",
    "    axes[1].set_ylabel(\"fit_times\")\n",
    "    axes[1].set_title(\"Scalability of the model\")\n",
    "\n",
    "    # Plot fit_time vs score\n",
    "    fit_time_argsort = fit_times_mean.argsort()\n",
    "    fit_time_sorted = fit_times_mean[fit_time_argsort]\n",
    "    test_scores_mean_sorted = test_scores_mean[fit_time_argsort]\n",
    "    test_scores_std_sorted = test_scores_std[fit_time_argsort]\n",
    "    axes[2].grid()\n",
    "    axes[2].plot(fit_time_sorted, test_scores_mean_sorted, \"o-\")\n",
    "    axes[2].fill_between(\n",
    "        fit_time_sorted,\n",
    "        test_scores_mean_sorted - test_scores_std_sorted,\n",
    "        test_scores_mean_sorted + test_scores_std_sorted,\n",
    "        alpha=0.1,\n",
    "    )\n",
    "    axes[2].set_xlabel(\"fit_times\")\n",
    "    axes[2].set_ylabel(\"Score\")\n",
    "    axes[2].set_title(\"Performance of the model\")\n",
    "\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T17:55:23.203344Z",
     "iopub.status.busy": "2022-02-16T17:55:23.20306Z",
     "iopub.status.idle": "2022-02-16T17:55:25.829985Z",
     "shell.execute_reply": "2022-02-16T17:55:25.829175Z",
     "shell.execute_reply.started": "2022-02-16T17:55:23.203314Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "y_pred=mlp.predict(X_test_pca)\n",
    "#confusion matrix\n",
    "fig3=plt.figure(4,figsize=(10,10))\n",
    "fig3.suptitle(\"confusion matrix mlp\")\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "print(cm)\n",
    "plt.subplot(221)\n",
    "df_cm = pd.DataFrame(cm, index = [i for i in range(2)],\n",
    "                  columns = [i for i in range(2)])\n",
    "sns.heatmap(df_cm, annot=True, annot_kws={\"size\": 16}, fmt='d')\n",
    "plt.title('confusion matrix')\n",
    "plt.xlabel('prediction')\n",
    "plt.ylabel('Actual');\n",
    "\n",
    "fig4=plt.figure(5,figsize=(10,10))\n",
    "fig4.suptitle(\"roc curve mlp\")\n",
    "#Roc curve\n",
    "plot_roc_curve(mlp,X_test_pca,y_test)\n",
    "\n",
    "fig5=plt.figure(6,fogsize=(10,10))\n",
    "plot_learning_curve(mlp,'Learning curve mlp',X_train_pca,y_train)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All features models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T18:01:02.848204Z",
     "iopub.status.busy": "2022-02-16T18:01:02.847908Z",
     "iopub.status.idle": "2022-02-16T18:01:54.826201Z",
     "shell.execute_reply": "2022-02-16T18:01:54.825634Z",
     "shell.execute_reply.started": "2022-02-16T18:01:02.848169Z"
    }
   },
   "outputs": [],
   "source": [
    "#-----------------------MLP grid search CV-----------------------------\n",
    "\n",
    "mlp2=make_pipeline(RobustScaler(),MLPClassifier(max_iter=10000))\n",
    "param_grid={\n",
    "            'mlpclassifier__hidden_layer_sizes':(range(1,4)),\n",
    "            'mlpclassifier__solver':['lbfgs','sgd'],\n",
    "            'mlpclassifier__activation':[\"logistic\", \"tanh\", \"relu\"]\n",
    "           }                             \n",
    "grid= GridSearchCV(mlp2,param_grid=param_grid,cv=5)\n",
    "grid.fit(X_train,y_train)\n",
    "print(\"best train cv score : {:.3f}, avec les paramÃ¨tres : {}\".format(grid.best_score_,grid.best_params_))\n",
    "mlp2=grid.best_estimator_\n",
    "print(\"test score {:.3f}\".format(mlp2.score(X_test,y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T18:04:34.346137Z",
     "iopub.status.busy": "2022-02-16T18:04:34.345345Z",
     "iopub.status.idle": "2022-02-16T18:04:53.751384Z",
     "shell.execute_reply": "2022-02-16T18:04:53.750373Z",
     "shell.execute_reply.started": "2022-02-16T18:04:34.346099Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "y_pred=mlp2.predict(X_test)\n",
    "#confusion matrix\n",
    "fig3=plt.figure(4,figsize=(10,10))\n",
    "fig3.suptitle(\"confusion matrix mlp\")\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "print(cm)\n",
    "plt.subplot(221)\n",
    "df_cm = pd.DataFrame(cm, index = [i for i in range(2)],\n",
    "                  columns = [i for i in range(2)])\n",
    "sns.heatmap(df_cm, annot=True, annot_kws={\"size\": 16}, fmt='d')\n",
    "plt.title('confusion matrix')\n",
    "plt.xlabel('prediction')\n",
    "plt.ylabel('Actual');\n",
    "\n",
    "fig4=plt.figure(5,figsize=(10,10))\n",
    "fig4.suptitle(\"roc curve mlp\")\n",
    "#Roc curve\n",
    "plot_roc_curve(mlp2,X_test,y_test)\n",
    "\n",
    "fig5=plt.figure(6,fogsize=(10,10))\n",
    "plot_learning_curve(mlp2,'Learning curve mlp',X_train,y_train)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
